{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQfsxvu2MrAc"
   },
   "source": [
    "MODULE 6 | LESSON 4\n",
    "\n",
    "# **Model Failure, Crises, and The Need for Data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6JWZbCYFhmI"
   },
   "source": [
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** |30 minutes|\n",
    "|**Prior Knowledge** |Financial Markets course|\n",
    "|**Keywords** |Model paradigm, Backfire\n",
    " |\n",
    "|  |  |\n",
    "\n",
    "\n",
    "*In the final lesson of this module, let's recap some of the key lessons we've learned about data and its role in helping to address the financial challenges we discussed in Financial Markets. Specifically, this lesson addresses model failure and crises, motivating the need for data.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tsZsezGth8R"
   },
   "source": [
    "Sometimes, models fail. Markets are not the problem; the simplifying representational lens through which we summarize, simplify, or systemize the world is the problem. Models that have worked for decades and that have been tested, validated, and replicated can fail. Models that are proven through derivation and published in peer-reviewed journals can fail. Models that have earned fame, numerous citations, and Nobel Prizes for their authors can fail. Models whose features are found in software and used worldwide can fail. How can this be?\n",
    "\n",
    "There are all kinds of models. Models exist for predicting volatility and options or for determining risk premium. There are models to trade based on value, which trade relatively infrequently. There are high-frequency trading models that work in fractions of a second. There are microstructural models that model the intricacies of orders on an exchange. There are global macroeconomic models that tackle GDP, employment, inflation, and monetary policy. Models come in all shapes and sizes.\n",
    "\n",
    "One thing that all models have in common is that they tend to provide insight into the challenges we’ve discussed: credit risk and financing, volatility, correlation, leverage, non-linearity, liquidity, and regulation. However, their results and interpretations can be misleading when those models fail.\n",
    "\n",
    "Let’s examine ten takeaways from model failure.\n",
    "\n",
    "# **1. Finance Is Not Physics**\n",
    "The laws of physics are not the laws in finance. Let’s be sure to distinguish what works in rational or theoretical models from what works in the real world. Finance is not physics, meaning financial models reflect human behavior, which itself is a combination of rationality and irrationality. As such, financial models may not work if they assume everyone is behaving rationally. Sometimes, markets oscillate between conditions of great efficiency and conditions that are characterized by extreme cognitive biases. (See Andrew Lo’s Adaptive Market Hypothesis https://web.mit.edu/Alo/www/Papers/JPM2004_Pub.pdf for an intriguing discussion of this oscillation).\n",
    "\n",
    "The irrational part is much newer to the field of economics than the rational assumptions. Only within the last 20 years have Nobel Prizes been awarded to researchers in behavioral economics (e.g., Kahneman, Thaler). Behavioral finance reminds us that many of the assumptions upon which finance is built are flawed in practice. Therefore, there are not immutable laws of finance like there are in the hard sciences. Some of these ideas were captured in a manifesto that was written after the Great Financial Crisis (Wilmott). The manifesto reminds us of the existence of human biases in decision-making, making any so-called financial laws non-reproducible.\n",
    "\n",
    "Consider the recent price surge in the stock price of Game Stop. Among many lessons we can learn, people can manipulate the stock market for reasons beyond risk return characteristics. Please see and read the article by Zhao (https://www.atlantis-press.com/proceedings/icemci-21/125966071).\n",
    "\n",
    "# **2. Leveraged positions can increase gains or aggravate losses.**\n",
    "Suppose you have a well-validated model that extracts alpha. You may be encouraged to use leverage to extract a greater size of that alpha. For example, you could invest 8x as much in the strategy, thinking you will earn 8x the net revenue. You could use leverage to put less down, borrow funds, and produce greater returns. Indeed, this strategy can achieve greater returns—or greater losses! However, one thing it will surely create is greater risk. The increased use of leverage creates more uncertainty around the expected value. Leveraged positions are indifferent to direction: they can increase your gains or deepen the losses.\n",
    "\n",
    "For more detailed examples, please read Hott's “Leverage and Risk Taking under Moral Hazard\" article (https://www.google.com/url?q=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10693-021-00359-8).\n",
    "\n",
    "# **3. It's easy to mistake variables as parameters: variables change, but parameters are constant.**\n",
    "How do we know what remains constant and what varies in a model? When you model a system, you choose some things as parameters and others as variables. Parameters are constants we estimate from historical data or perhaps imply from market prices. Variables are dynamic quantities that change with time. It's easy to mistake a variable as a parameter. In financial settings, one can easily call a variable a parameter.\n",
    "\n",
    "Without strong mathematical and statistical skills, we are likely to assume many things are constant: volatility, interest rates, correlations, even distributions. The stronger our analytical toolkit, the greater the extent by which we can successfully relax assumptions and upgrade our models by having quantities like volatility or interest rates be variables instead of parameters. Ironically, we may want some quantities to be parameters instead of variables. The nontechnical person can only rely on models others have built. The technical person can not only use models but they can also adapt models for their own use by relaxing assumptions, relying on more powerful algorithms, and using advanced methods of calibration and optimization. Moreover, if they add their own creativity, critical thinking, and subject matter expertise, they will be able to create custom models.\n",
    "\n",
    "This last point justifies the need for a master’s program, not just a single course or a video on \"how to be a financial engineer.\" The material provides the theory and implementation of tools that are then used to illustrate problem solving in financial engineering. If a constant volatility model proves to be inadequate (as it is when attempting to reproduce the volatility smile), then we can upgrade the model to a 2-factor stochastic volatility model that requires mathematical know-how, statistical calibration, and computational implementation. The same is true for dynamic interest rates, dynamic correlations, or any other quantity that we wish to express as time varying. The cost of more sophisticated models is the foundation to understanding them, the extra computational complexity to implement them, and the insight to know when they work and when they don’t.\n",
    "\n",
    "# **4. We may not use models correctly, either failing to understand their instructions or limitations.**\n",
    "Models may work properly, but we may not use them properly! We may underestimate a parameter, or we may overestimate it. We may fail to follow instructions correctly or to understand the assumptions imposed by the model. We may use a model under conditions that it didn’t expect. It’s not that the model is wrong. It's that we're using it incorrectly.\n",
    "\n",
    "Clearly, one example would be simple negligence. Suppose we are submitting a trade to an exchange. Here, we are using an order as a model. For a given limit order, we specify the price and quantity. Suppose we want to sell 1 unit at 610,000 yen. Imagine if we mixed up price and quantity! Mistakenly, we submit an order to sell 610,000 at 1 yen. Implausible? This happened in December 2005. The order was quite unusual. The price was nowhere near 1 yen, but 610,000 yen which is $5,041. Also, the number of shares in the order was more than 40 times that amount held by the company. Nevertheless, the exchange did not reject the order. The costly mistake was nearly a quarter of a billion dollars. This type of error is attributed to operational risk. How does the software get placed in production without the oversight of testing and validation? Now imagine a model with thousands of moving parts and trying to assess whether there are fundamental flaws in it.\n",
    "\n",
    "A more difficult error is if the assumptions or conditions under which a model was built are not followed. Unfortunately, there are tragic illustrations. In 1986, the Space Shuttle Challenger exploded, killing all seven crew members aboard. Investigations followed. The culprit was a piece of equipment—the O-ring. An explanation of what went wrong was given by one of the most brilliant physicists in the world, Richard Feynman. Appearing before a panel to explain what went wrong, Feynman decided to demonstrate the problem. While he was waiting to speak, he put these O-rings in ice water. When it was Dr. Feynman’s turn to speak, he took the O-ring out of the ice water and showed that the O-ring lacked the assumed resilience. These O-rings were tested in Florida at warm temperatures, temperatures well above the freezing point. But on that launch day in January, Florida was unseasonably cold—at a temperature low enough where the O-rings were never tested.\n",
    "\n",
    "This is an example of applying the results of a model at a temperature where it was scarcely tested. In statistical terms, this is known as extrapolation. The testing didn't consider how effectively the O-rings would work in an environment that was 20 degrees colder (11 degrees Celsius colder) than normal. The data and story are explained in the article by Wujek (https://www.google.com/url?q=https%3A%2F%2Fonlineethics.org%2Fcases%2Fnumerical-design-problems-ethical-content%2Fchallenger-o-ring-data-analysis). Please read it. Model failure can be very expensive, with lives and fortunes at stake.\n",
    "\n",
    "# **5. Liquidity can make models achieve unexpected results.**\n",
    "Suppose you have a great trade. Now you’d like to scale it up by buying more. Taking too big a position starts to question the security’s liquidity: is there market impact? It is possible to turn a profitable trade into an unprofitable one by scaling it too much, as the market impact competes with the strategy’s alpha. Every trader has a model that extracts alpha from the market. As they trade more and more, they face slippage, the market impact that increases the price entering the trade and lowers the price while exiting the trade. Is there a corresponding model for its market impact? Whether buying or selling, market impact cause prices to move in a way that eats into the strategy’s alpha. Left unchecked, the slippage can outweigh any advantage. We’ll discuss the Zillow case following this.\n",
    "\n",
    "\n",
    "# **6. The existence of a model, or the conviction of its author, doesn't mean it works in practice.**\n",
    "“We’ve been using this model since forever.” “This is the model everyone uses.” “This model has been around longer than you’ve been alive!” “Why would I trust your model when famous people and billions of dollars have used this model?”\n",
    "\n",
    "You're given a model and you're often told that it works. It gives you a full sense of security. You'll see this a lot in this program. For example, in Derivative Pricing, you’ll price an option with a model that has been around for 50 years. You compute prices and sensitivities but initially don’t question too many things. Over time, you realize some of the assumptions of the model are flawed. For example, you’re told volatility is constant. Then, you realize later that’s not what is observed in the option market. What makes people cling to models even if they see there is little evidence for it? We’ll discuss different cognitive and behavioral biases in Portfolio Management. For example, overconfidence bias can blind someone to facts because of their education, experience, and position. Markets can be humbling.\n",
    "\n",
    "Just because models are old, Nobel Prize-winning, universal, easily implemented, frequently cited, massively popular, or intuitive doesn’t necessarily make them the best model to use. The dynamics of the market change. Consider models for equities. Equities are impacted by central bank decisions. Additions and deletions in the underlying major indices can affect equities. Option expiration has an effect on the underlying equities market. Even the existence and expansion of cryptocurrencies affect how equity markets trade! Valuation models that traditionally work in equities trading may be temporarily disrupted (if not broken) by the expansion and implosion of the cryptocurrency exchanges. As an engineer, you're using data and modeling capabilities to determine sensitivities, structural breaks, or regime shifts. Ironically, you might use more models sometimes to effectively assess whether the models that you have are appropriate. In some drastic conditions or cases, you may need to have discussions with researchers, portfolio managers, and risk managers to determine if the models lack credibility or validation. Blind reliance on untested models can give a false sense of security.\n",
    "\n",
    "Almost no one gets a memo saying, “This model no longer works. Please use another one.” Models may be used long after their “expiration date.” Learn to think critically about models. Don’t justify use by the appeal to authority fallacy.\n",
    "\n",
    "# **7. Models assuming linearity may fail due to non-linearities, especially when there is leverage.**\n",
    "Often, we assume a model has linearities: we increase an input, we get a known increase in the output. Suppose the ratio is 1.5. Then, when we double the output, we get triple the output. Other times, we see there are lots of non-linearities. As we’ve seen, convexity causes small changes to produce small results, but bigger changes produce disproportionately bigger results.\n",
    "\n",
    "Likewise, the piecewise nonlinearity of an option’s payoff can drive an option to be in the money or out of the money. It becomes very important whether the increase brings you on one side of strike or the other! Market impact is an example of a sensitivity that may start out linear (for relatively small amounts traded) and become very non-linear for larger amounts traded. The mistake is usually a gross underestimation of a cost, loss, or risk that can cause a crisis.\n",
    "\n",
    "# **8. Models are built on assumptions, so be aware of the conditions.**\n",
    "Every model has assumptions. Some people are unaware of these assumptions because they require a deeper level of understanding than simply using the model by running code. There are conditions that may warrant the use (or void the use!) such as Gaussian vs. non-Gaussian, stationary vs. non-stationary, momentum vs. mean-reversion, non-negativity vs negativity. Very often, we have assumptions that can make or break the model. Sometimes, we have conditions that invalidate the model. A common error is running regressions on non-stationary processes and finding what appears to be a meaningful test-statistic, only to realize that this could be the result of spurious regressions. This type of mistake is more of an operator error than a model failure, in that the model was never appropriate to use in the first place. This point makes it essential to build a solid foundation. There are many students and workers who simply go through the motions of running a model without assessing whether it was appropriate in the first place. This failure is easily remedied by studying the underlying mathematical properties of the model.\n",
    "\n",
    "Other conditions simply relate to the natural boundaries of the target variable in question. A model that predicts a negative stock price is questionable—stock prices cannot be negative. Yet, a model that forbids a negative interest rate is equally questionable—as negative interest rates can and do exist. Likewise, oil price futures can go negative. It's not always easy to determine which quantities should be strictly non-negative.\n",
    "\n",
    "# **9. Every model is a paradigm that needs validation to be properly assessed.**\n",
    "Models reflect paradigms. Very often, you will see the world through the very model you are using. For example, if you believe the returns of a stock are Gaussian, then you will call a very large loss a 5 sigma move—a very rare event indeed. Yet, what if the distribution is not truly Gaussian? Five sigma events are highly unlikely. Many return distributions have excess kurtosis, making them non-Gaussian. So then, we should put away our Gaussian glasses and put on a pair of glasses that views the world through a more appropriate distribution.\n",
    "\n",
    "Models need validation. It's very hard to know if your model is wrong if somehow you view the world as if the assumptions are automatically true. Banks are allowed to use internal models for running stress tests on their credit risks, but these models need extensive validation. When you look at things like central banks or Basel regulation, they're requiring certain criteria to validate the model.\n",
    "\n",
    "As a student in the program, you will learn foundational models and then add complexity to them. In the Machine Learning track, for example, you review least squares and then learn numerous extensions. There are two insights that guide this process. First, learning simpler models helps to build the foundation for learning more advanced models. Second, if simple models work well, we can use them. Many times, the simple model may work best! However, if these models underfit, then we have other methodologies we can use. Understanding the “why” and “how” behind models will hone your skill set.\n",
    "\n",
    "# **10. Models can backfire.**\n",
    "Unfortunately, models can backfire. A model intended to reduce risk may increase it. A model intended to increase returns reduces them in practice. Unfortunately, aside from risk, remember that models may have uncertainty: we may not know the distribution or even the outcomes. Let’s consider a real-world example.\n",
    "\n",
    "Recently, Zillow undertook a strategy itself that backfired. Zillow is an analytics provider of real-estate information. At some point, they decided to undertake a strategy where they would flip residential real estate. After all, they had massive amounts of data. Zillow thought that this data would give them an edge in the marketplace because few other companies had access to this data. This data didn’t only include list prices and closing prices, but also traffic, searches, and other data collected from their widely popular search portal. For example, local areas or even streets that seemed to have lots of searches became highly prized properties. Zillow believed they had a keen sense of which properties were popular and would be sold for at or over list price. Furthermore, they had a proprietary algorithm for the valuation of a home—their so-called Zestimate number.\n",
    "\n",
    "Zillow aggressively bought up properties, attempting to flip them. They purchased homes and thought they could flip them. They did a little market manipulation by gently increasing the prices as they bought, and then they hoped to create a trend that would establish all those homes as being worth more. Unfortunately, the strategy became apparent to the market. It created very bad sentiment that they were manipulating house prices. They also underestimated the lack of diversification: their purchases tended to cluster around hot spots. They also underestimated liquidity risk. It took longer than expected to make improvements and flip the house. They also bought homes a bit late into the bubble, paying near the top of the market. As they sold their inventory, they were selling for an average of about $80,000 less per house. In total, they lost hundreds of millions of dollars. They had to lay off staff, and they eventually exited the investment business.\n",
    "\n",
    "Given data, access, experience, and valuation models, they failed to\n",
    "incorporate key issues like correlation, liquidity, and reputation. The advantage they believed to have ultimately backfired into a disastrous investment.\n",
    "\n",
    "Models can backfire because it's not so easy to know our influence on the market.\n",
    "\n",
    "# **11. Conclusion**\n",
    "Oftentimes, in their capstone projects, students will run a back test, assuming they can buy and sell at the closing price. They’ll use a staggering amount of funds and report extraordinary results that show no market impact or bid-ask spread. They’ll assume that their back test on paper reflects exactly what will happen. But by participating in the market, they would definitely encounter bid-ask spread and potentially market impact, depending on the size of their trade.\n",
    "\n",
    "As previously, one thing that all models have in common is that they tend to provide insight into the challenges we’ve discussed: credit risk and financing, volatility, correlation, leverage, non-linearity, liquidity, and regulation. However, when misued their results and interpretations are irrelevant at best (that is, simply unusable) and downright misleading at worst.  Building that false sense of security can lead to widespread systemic risk.\n",
    "\n",
    "In this final lesson, we saw models fail for three overarching reasons:\n",
    "\n",
    "1. they may be specified incorrectly,\n",
    "2. they may be used incorrectly, and\n",
    "3. they may be used inappropriately.\n",
    "\n",
    "With these new insights, let us continue.  We will accept these financial challenges. We will leverage our experience of empirical analysis by using data in a variety of models that will take us on multi-semester journey through models from econometrics, time series analysis, stochastic processing, machine learning, deep learning, and moer.  Whatever models we may be using, let's be mindful of how we use (and attempt not to misuse) them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KvTOJQ-GFrc1"
   },
   "source": [
    "---\n",
    "Copyright 2024 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "19MugEcC2N5w8Oqq1cnTWhcbRmwWH1gVW",
     "timestamp": 1731093912694
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
